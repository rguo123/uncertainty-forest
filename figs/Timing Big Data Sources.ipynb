{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "import mixed\n",
    "import time\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "### UF CODE\n",
    "'''\n",
    "Primary Author: Will LeVine\n",
    "Email: levinewill@icloud.com\n",
    "'''\n",
    "\n",
    "#Model\n",
    "from sklearn.ensemble import BaggingClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "#Infrastructure\n",
    "from sklearn.base import BaseEstimator, ClassifierMixin\n",
    "from sklearn.utils.validation import NotFittedError\n",
    "\n",
    "#Data Handling\n",
    "from sklearn.utils.validation import (\n",
    "    check_X_y,\n",
    "    check_array,\n",
    "    NotFittedError,\n",
    ")\n",
    "from sklearn.utils.multiclass import check_classification_targets\n",
    "\n",
    "#Utils\n",
    "from joblib import Parallel, delayed\n",
    "import numpy as np\n",
    "\n",
    "def _finite_sample_correction(posteriors, num_points_in_partition, num_classes):\n",
    "    '''\n",
    "    encourage posteriors to approach uniform when there is low data\n",
    "    '''\n",
    "    correction_constant = 1 / (num_classes * num_points_in_partition)\n",
    "\n",
    "    zero_posterior_idxs = np.where(posteriors == 0)[0]\n",
    "    posteriors[zero_posterior_idxs] = correction_constant\n",
    "    \n",
    "    posteriors /= sum(posteriors)\n",
    "    \n",
    "    return posteriors\n",
    "\n",
    "class UncertaintyForest(BaseEstimator, ClassifierMixin):\n",
    "    '''\n",
    "    based off of https://arxiv.org/pdf/1907.00325.pdf\n",
    "    '''\n",
    "    def __init__(\n",
    "        self,\n",
    "        max_depth=30,\n",
    "        min_samples_leaf=1,\n",
    "        max_samples = 0.63,\n",
    "        max_features_tree = \"auto\",\n",
    "        n_estimators=100,\n",
    "        bootstrap=False,\n",
    "        parallel=True,\n",
    "        n_jobs = None):\n",
    "\n",
    "        #Tree parameters.\n",
    "        self.max_depth = max_depth\n",
    "        self.min_samples_leaf = min_samples_leaf\n",
    "        self.max_features_tree = max_features_tree\n",
    "\n",
    "        #Bag parameters\n",
    "        self.n_estimators = n_estimators\n",
    "        self.bootstrap = bootstrap\n",
    "        self.max_samples = max_samples\n",
    "\n",
    "        #Model parameters.\n",
    "        self.parallel = parallel\n",
    "        if self.parallel and n_jobs == None:\n",
    "            self.n_jobs = self.n_estimators\n",
    "        else:\n",
    "            self.n_jobs = n_jobs\n",
    "        self.fitted = False\n",
    "\n",
    "    def _check_fit(self):\n",
    "        '''\n",
    "        raise a NotFittedError if the model isn't fit\n",
    "        '''\n",
    "        if not self.fitted:\n",
    "                msg = (\n",
    "                        \"This %(name)s instance is not fitted yet. Call 'fit' with \"\n",
    "                        \"appropriate arguments before using this estimator.\"\n",
    "                )\n",
    "                raise NotFittedError(msg % {\"name\": type(self).__name__})\n",
    "\n",
    "    def transform(self, X):\n",
    "        '''\n",
    "        get the estimated posteriors across trees\n",
    "        '''\n",
    "        X = check_array(X)\n",
    "                \n",
    "        def worker(tree_idx, tree):\n",
    "            #get the nodes of X\n",
    "            # Drop each estimation example down the tree, and record its 'y' value.\n",
    "            return tree.apply(X)\n",
    "            \n",
    "\n",
    "        if self.parallel:\n",
    "            return np.array(\n",
    "                    Parallel(n_jobs=self.n_jobs)(\n",
    "                            delayed(worker)(tree_idx, tree) for tree_idx, tree in enumerate(self.ensemble.estimators_)\n",
    "                    )\n",
    "            )         \n",
    "        else:\n",
    "            return np.array(\n",
    "                    [worker(tree_idx, tree) for tree_idx, tree in enumerate(self.ensemble.estimators_)]\n",
    "                    )\n",
    "        \n",
    "    def get_transformer(self):\n",
    "        return lambda X : self.transform(X)\n",
    "        \n",
    "    def vote(self, nodes_across_trees):\n",
    "        return self.voter.predict(nodes_across_trees)\n",
    "        \n",
    "    def get_voter(self):\n",
    "        return self.voter\n",
    "        \n",
    "                        \n",
    "    def fit(self, X, y):\n",
    "\n",
    "        #format X and y\n",
    "        X, y = check_X_y(X, y)\n",
    "        check_classification_targets(y)\n",
    "        self.classes_, y = np.unique(y, return_inverse=True)\n",
    "        \n",
    "        #define the ensemble\n",
    "        self.ensemble = BaggingClassifier(\n",
    "            DecisionTreeClassifier(\n",
    "                max_depth=self.max_depth,\n",
    "                min_samples_leaf=self.min_samples_leaf,\n",
    "                max_features=self.max_features_tree\n",
    "            ),\n",
    "            n_estimators=self.n_estimators,\n",
    "            max_samples=self.max_samples,\n",
    "            bootstrap=self.bootstrap,\n",
    "            n_jobs = self.n_jobs\n",
    "        )\n",
    "        \n",
    "        #fit the ensemble\n",
    "        self.ensemble.fit(X, y)\n",
    "        \n",
    "        class Voter(BaseEstimator):\n",
    "            def __init__(self, estimators_samples_, classes, parallel, n_jobs):\n",
    "                self.n_estimators = len(estimators_samples_)\n",
    "                self.classes_ = classes\n",
    "                self.parallel = parallel\n",
    "                self.estimators_samples_ = estimators_samples_\n",
    "                self.n_jobs = n_jobs\n",
    "            \n",
    "            def fit(self, nodes_across_trees, y, fitting = False):\n",
    "                self.tree_idx_to_node_ids_to_posterior_map = {}\n",
    "\n",
    "                def worker(tree_idx):\n",
    "                    nodes = nodes_across_trees[tree_idx]\n",
    "                    oob_samples = np.delete(range(len(nodes)), self.estimators_samples_[tree_idx])\n",
    "                    cal_nodes = nodes[oob_samples] if fitting else nodes\n",
    "                    y_cal = y[oob_samples] if fitting else y                    \n",
    "                    \n",
    "                    #create a map from the unique node ids to their classwise posteriors\n",
    "                    node_ids_to_posterior_map = {}\n",
    "\n",
    "                    #fill in the posteriors \n",
    "                    for node_id in np.unique(cal_nodes):\n",
    "                        cal_idxs_of_node_id = np.where(cal_nodes == node_id)[0]\n",
    "                        cal_ys_of_node = y_cal[cal_idxs_of_node_id]\n",
    "                        class_counts = [len(np.where(cal_ys_of_node == y)[0]) for y in np.unique(y) ]\n",
    "                        posteriors = np.nan_to_num(np.array(class_counts) / np.sum(class_counts))\n",
    "\n",
    "                        #finite sample correction\n",
    "                        posteriors_corrected = _finite_sample_correction(posteriors, len(cal_idxs_of_node_id), len(self.classes_))\n",
    "                        node_ids_to_posterior_map[node_id] = posteriors_corrected\n",
    "\n",
    "                    #add the node_ids_to_posterior_map to the overall tree_idx map \n",
    "                    self.tree_idx_to_node_ids_to_posterior_map[tree_idx] = node_ids_to_posterior_map\n",
    "                    \n",
    "                for tree_idx in range(self.n_estimators):\n",
    "                        worker(tree_idx)\n",
    "                return self\n",
    "                        \n",
    "                        \n",
    "            def predict_proba(self, nodes_across_trees):\n",
    "                def worker(tree_idx):\n",
    "                    #get the node_ids_to_posterior_map for this tree\n",
    "                    node_ids_to_posterior_map = self.tree_idx_to_node_ids_to_posterior_map[tree_idx]\n",
    "\n",
    "                    #get the nodes of X\n",
    "                    nodes = nodes_across_trees[tree_idx]\n",
    "\n",
    "                    posteriors = []\n",
    "                    node_ids = node_ids_to_posterior_map.keys()\n",
    "\n",
    "                    #loop over nodes of X\n",
    "                    for node in nodes:\n",
    "                        #if we've seen this node before, simply get the posterior\n",
    "                        if node in node_ids:\n",
    "                            posteriors.append(node_ids_to_posterior_map[node])\n",
    "                        #if we haven't seen this node before, simply use the uniform posterior \n",
    "                        else:\n",
    "                            posteriors.append(np.ones((len(np.unique(self.classes_)))) / len(self.classes_))\n",
    "                    return posteriors\n",
    "\n",
    "                if self.parallel:\n",
    "                    return np.mean(\n",
    "                            Parallel(n_jobs=self.n_jobs)(\n",
    "                                    delayed(worker)(tree_idx) for tree_idx in range(self.n_estimators)\n",
    "                            ), axis = 0\n",
    "                    )\n",
    "\n",
    "                else:\n",
    "                    return np.mean(\n",
    "                            [worker(tree_idx) for tree_idx in range(self.n_estimators)], axis = 0)\n",
    "                \n",
    "        #get the nodes of the calibration set\n",
    "        nodes_across_trees = self.transform(X) \n",
    "        self.voter = Voter(estimators_samples_ = self.ensemble.estimators_samples_, classes = self.classes_, parallel = self.parallel, n_jobs = self.n_jobs)\n",
    "        self.voter.fit(nodes_across_trees, y, fitting = True)\n",
    "        self.fitted = True\n",
    "\n",
    "    def predict(self, X):\n",
    "        return self.classes_[np.argmax(self.predict_proba(X), axis=-1)]\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.voter.predict_proba(self.transform(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_big_data(n_samples=10000, n_features=100):\n",
    "    X = np.random.rand(n_samples, n_features)\n",
    "    y = np.random.binomial(1, .5, n_samples)\n",
    "    return X, np.ravel(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_samples = 10000000\n",
    "n_features = 50000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, y = generate_big_data(n_samples=n_samples, n_features=n_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = UncertaintyForest(parallel=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38.498706102371216\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "model.fit(X, y)\n",
    "end = time.time()\n",
    "uf_elapsed = end - start\n",
    "print(uf_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "68.04642105102539\n"
     ]
    }
   ],
   "source": [
    "start = time.time()\n",
    "mixed.KSG(X, y)\n",
    "end = time.time()\n",
    "ksg_elapsed = end - start\n",
    "print(ksg_elapsed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        n_samples  n_features         uf        ksg\n",
      "values   10000000       50000  38.498706  68.046421\n"
     ]
    }
   ],
   "source": [
    "# Stitch it together in a dataframe.\n",
    "runtime_dict = {\n",
    "    \"n_samples\": n_samples,\n",
    "    \"n_features\": n_features,\n",
    "    \"uf\": uf_elapsed,\n",
    "    \"ksg\": ksg_elapsed\n",
    "}\n",
    "\n",
    "table = pd.DataFrame(runtime_dict, index=[\"values\"])\n",
    "table.to_csv(\"runtime_table.csv\", index = False)\n",
    "print(table)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
